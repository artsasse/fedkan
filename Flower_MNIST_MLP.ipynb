{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artsasse/fedkan/blob/main/Flower_MNIST_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-k1Z1KHI6EC"
      },
      "source": [
        "# Using a Federated MLP to classify MNIST\n",
        "\n",
        "This notebook is based mainly on the Flower Tutorial \"Use a federated learning strategy\", found in https://flower.ai/docs/framework/tutorial-series-use-a-federated-learning-strategy-pytorch.html ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYOHo7tsI6EE"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BOUqWBtaI6EE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c3e9ce-1534-4b4c-e94d-b26fde6889db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.3.1 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install -q flwr[simulation] flwr-datasets[vision] torch torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y25quxLmI6EF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfa574d9-9518-4bed-960b-22ed318d4f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on cpu\n",
            "Flower 1.10.0 / PyTorch 2.4.0+cu121\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import flwr\n",
        "from flwr.client import Client, ClientApp, NumPyClient\n",
        "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
        "from flwr.server.strategy import FedAvg, FedAdagrad\n",
        "from flwr.simulation import run_simulation\n",
        "from flwr_datasets import FederatedDataset\n",
        "from flwr.common import ndarrays_to_parameters, NDArrays, Scalar, Context\n",
        "\n",
        "# Preciso alterar o runtime para usar GPU (SASSE)\n",
        "# DEVICE = torch.device(\"cuda\")  # Try \"cuda\" to train on GPU\n",
        "DEVICE = torch.device(\"cpu\")  # Run training on CPU\n",
        "print(f\"Training on {DEVICE}\")\n",
        "print(f\"Flower {flwr.__version__} / PyTorch {torch.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6jR8cN7I6EG"
      },
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tc70GEH5I6EH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4231a99d-e495-4caa-d960-63ef0c64d5dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "NUM_PARTITIONS = 10\n",
        "# SASSE - confirmar o batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def load_datasets(partition_id: int, num_partitions: int):\n",
        "\n",
        "    pytorch_transforms = transforms.Compose(\n",
        "        [transforms.ToTensor(),\n",
        "         transforms.Normalize((0.5,), (0.5,)),\n",
        "         transforms.Lambda(lambda x: torch.flatten(x))  # Flatten the image into a 1D tensor\n",
        "         ]\n",
        "    )\n",
        "\n",
        "    def apply_transforms(batch):\n",
        "        # Instead of passing transforms to MNIST(..., transform=transform)\n",
        "        # we will use this function to dataset.with_transform(apply_transforms)\n",
        "        # The transforms object is exactly the same\n",
        "        batch[\"image\"] = [pytorch_transforms(img) for img in batch[\"image\"]]\n",
        "        return batch\n",
        "\n",
        "    fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": num_partitions})\n",
        "    partition = fds.load_partition(partition_id).with_transform(apply_transforms)\n",
        "    trainloader = DataLoader(partition, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    testset = fds.load_split(\"test\").with_transform(apply_transforms)\n",
        "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "    return trainloader, testloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyV6x7CAI6EH"
      },
      "source": [
        "## Model training/evaluation (PyTorch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "UkgcOZYyI6EH"
      },
      "outputs": [],
      "source": [
        "# class Net(nn.Module):\n",
        "\n",
        "#     def __init__(self) -> None:\n",
        "#         super(Net, self).__init__()\n",
        "#         self.layer1 = nn.Linear(28 * 28, 200)  # 28 x 28 pixels\n",
        "#         self.layer2 = nn.Linear(200, 200)  # 2 hidden layers with 200 neurons each\n",
        "#         self.layer3 = nn.Linear(200, 10)  # 10 classes\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "#     def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "#         x = self.relu(self.layer1(x))\n",
        "#         x = self.relu(self.layer2(x))\n",
        "#         x = self.softmax(self.layer3(x))\n",
        "#         return x\n",
        "\n",
        "class Net(KAN):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__([28 * 28, 24, 24, 10])\n",
        "\n",
        "\n",
        "def get_parameters(net) -> List[np.ndarray]:\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
        "\n",
        "\n",
        "def set_parameters(net, parameters: List[np.ndarray]):\n",
        "    params_dict = zip(net.state_dict().keys(), parameters)\n",
        "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "    net.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "\n",
        "def train(net, trainloader, epochs: int):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    # Será que Adam e SGD influenciam a KAN? (SASSE)\n",
        "    # Estão usando o default para learning rate (lr) e momentum\n",
        "    # Um dos requisitos para garantir a convergencia é lr decrescente\n",
        "    optimizer = torch.optim.Adam(net.parameters())\n",
        "    net.train()\n",
        "    for epoch in range(epochs):\n",
        "        correct, total, epoch_loss = 0, 0, 0.0\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"image\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Metrics\n",
        "            epoch_loss += loss\n",
        "            total += labels.size(0)\n",
        "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
        "        epoch_loss /= len(trainloader.dataset)\n",
        "        epoch_acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n",
        "\n",
        "\n",
        "def test(net, testloader):\n",
        "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, total, loss = 0, 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in testloader:\n",
        "            images, labels = batch[\"image\"], batch[\"label\"]\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    loss /= len(testloader.dataset)\n",
        "    accuracy = correct / total\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KAN Model:"
      ],
      "metadata": {
        "id": "3G2tT2DnYos9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/Blealtan/efficient-kan.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "swBXPXzOYqY6",
        "outputId": "6d4d1b70-fdc0-42ae-adf7-2377d58852fe"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Blealtan/efficient-kan.git\n",
            "  Cloning https://github.com/Blealtan/efficient-kan.git to /tmp/pip-req-build-moejhply\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Blealtan/efficient-kan.git /tmp/pip-req-build-moejhply\n",
            "  Resolved https://github.com/Blealtan/efficient-kan.git to commit 7b6ce1c87f18c8bc90c208f6b494042344216b11\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from efficient-kan==0.1.0) (2.4.0+cu121)\n",
            "Collecting pytest>=8.2.0 (from efficient-kan==0.1.0)\n",
            "  Downloading pytest-8.3.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from efficient-kan==0.1.0) (4.66.5)\n",
            "Requirement already satisfied: torchvision>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from efficient-kan==0.1.0) (0.19.0+cu121)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (24.1)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest>=8.2.0->efficient-kan==0.1.0) (2.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->efficient-kan==0.1.0) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->efficient-kan==0.1.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->efficient-kan==0.1.0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->efficient-kan==0.1.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->efficient-kan==0.1.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->efficient-kan==0.1.0) (2024.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.18.0->efficient-kan==0.1.0) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.18.0->efficient-kan==0.1.0) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->efficient-kan==0.1.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->efficient-kan==0.1.0) (1.3.0)\n",
            "Downloading pytest-8.3.2-py3-none-any.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: efficient-kan\n",
            "  Building wheel for efficient-kan (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficient-kan: filename=efficient_kan-0.1.0-py3-none-any.whl size=5732 sha256=3ef1a2ecc035552022ca1dbb071a4d2df50f59173e279c345e9b8afd624d4270\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t2mu_y_a/wheels/b0/fb/12/d71ea36fa3e79f9e00b3d4c6ddd882c802d9a64f2ebe831866\n",
            "Successfully built efficient-kan\n",
            "Installing collected packages: pytest, efficient-kan\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 7.4.4\n",
            "    Uninstalling pytest-7.4.4:\n",
            "      Successfully uninstalled pytest-7.4.4\n",
            "Successfully installed efficient-kan-0.1.0 pytest-8.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from efficient_kan import KAN"
      ],
      "metadata": {
        "id": "6bVhUvw_YoUe"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flower Architecture"
      ],
      "metadata": {
        "id": "CnePIVzhvnwa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa_57hXVI6EH"
      },
      "source": [
        "### Flower client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "vmaFziBmI6EH"
      },
      "outputs": [],
      "source": [
        "class FlowerClient(NumPyClient):\n",
        "    def __init__(self, pid, net, trainloader, valloader=None):\n",
        "        self.pid = pid  # partition ID of a client\n",
        "        self.net = net\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        print(f\"[Client {self.pid}] get_parameters\")\n",
        "        return get_parameters(self.net)\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        # Read values from config\n",
        "        server_round = config[\"server_round\"]\n",
        "        local_epochs = config[\"local_epochs\"]\n",
        "\n",
        "        # Use values provided by the config\n",
        "        print(f\"[Client {self.pid}, round {server_round}] fit, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        train(self.net, self.trainloader, epochs=local_epochs)\n",
        "        return get_parameters(self.net), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        print(f\"[Client {self.pid}] evaluate, config: {config}\")\n",
        "        set_parameters(self.net, parameters)\n",
        "        loss, accuracy = test(self.net, self.valloader)\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}\n",
        "\n",
        "\n",
        "def client_fn(context: Context) -> Client:\n",
        "    net = Net().to(DEVICE)\n",
        "    partition_id = context.node_config[\"partition-id\"]\n",
        "    num_partitions = context.node_config[\"num-partitions\"]\n",
        "    trainloader, _ = load_datasets(partition_id, num_partitions)\n",
        "    return FlowerClient(partition_id, net, trainloader).to_client()\n",
        "\n",
        "\n",
        "# Create the ClientApp\n",
        "client = ClientApp(client_fn=client_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-JVaStsI6EI"
      },
      "source": [
        "### Server-side parameter **initialization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "yXaOojMGI6EI"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the model and get the parameters\n",
        "initial_model = Net()\n",
        "params = get_parameters(initial_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Get number of parameters"
      ],
      "metadata": {
        "id": "OaJ69wiQKyRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in initial_model.parameters())\n",
        "print(f\"Total number of parameters: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AycnSOwcBs3q",
        "outputId": "cce7e13a-f389-4e2b-f21e-cee6dcfd2617"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of parameters: 196320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7EY7Ev5I6EJ"
      },
      "source": [
        "### Server-side parameter **evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "qIXUNjPsI6EJ"
      },
      "outputs": [],
      "source": [
        "# The `evaluate` function will be called by Flower after every round\n",
        "def evaluate(\n",
        "    server_round: int,\n",
        "    parameters: NDArrays,\n",
        "    config: Dict[str, Scalar],\n",
        ") -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
        "    net = Net().to(DEVICE)\n",
        "    _, testloader = load_datasets(0, NUM_PARTITIONS)\n",
        "    set_parameters(net, parameters)  # Update model with the latest parameters\n",
        "    loss, accuracy = test(net, testloader)\n",
        "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
        "    return loss, {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gttp2GVqI6EJ"
      },
      "source": [
        "### Training **Configuration** (e.g. epochs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "vuHrYQVYI6EJ"
      },
      "outputs": [],
      "source": [
        "def fit_config(server_round: int):\n",
        "    \"\"\"Return training configuration dict for each round.\n",
        "\n",
        "    Perform two rounds of training with one local epoch, increase to two local\n",
        "    epochs afterwards.\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        \"server_round\": server_round,  # The current round of federated learning\n",
        "        \"local_epochs\": 1 if server_round < 2 else 2,\n",
        "    }\n",
        "    return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzF0C1qhI6EJ"
      },
      "source": [
        "### Flower **Server**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "SXvblF7nI6EJ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def server_fn(context: Context) -> ServerAppComponents:\n",
        "    # Create FedAvg strategy\n",
        "    strategy = FedAvg(\n",
        "        fraction_fit=0.3,\n",
        "        fraction_evaluate=0,\n",
        "        min_fit_clients=3,\n",
        "        min_evaluate_clients=0,\n",
        "        min_available_clients=NUM_PARTITIONS,\n",
        "        initial_parameters=ndarrays_to_parameters(params),\n",
        "        evaluate_fn=evaluate,\n",
        "        on_fit_config_fn=fit_config,  # Pass the fit_config function\n",
        "    )\n",
        "    config = ServerConfig(num_rounds=3)\n",
        "    return ServerAppComponents(strategy=strategy, config=config)\n",
        "\n",
        "\n",
        "# Create the ServerApp\n",
        "server = ServerApp(server_fn=server_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation"
      ],
      "metadata": {
        "id": "GTENQaquvyQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Simulation"
      ],
      "metadata": {
        "id": "097-NdhcvNJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_PARTITIONS = 10"
      ],
      "metadata": {
        "id": "lw2O-ztPdLfl"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backend_config = {\"client_resources\": None}\n",
        "# if DEVICE.type == \"cuda\":\n",
        "#     backend_config = {\"client_resources\": {\"num_gpus\": 1}}\n",
        "\n",
        "# Run simulation\n",
        "run_simulation(\n",
        "    server_app=server,\n",
        "    client_app=client,\n",
        "    num_supernodes=NUM_PARTITIONS,\n",
        "    backend_config=backend_config,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRDtQsvsvMUN",
        "outputId": "0090c37d-f245-46e5-cc2c-97ebedfc05a7"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=3, no round_timeout\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "\u001b[36m(pid=15691)\u001b[0m 2024-08-27 00:23:02.751760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[36m(pid=15691)\u001b[0m 2024-08-27 00:23:02.800286: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[36m(pid=15691)\u001b[0m 2024-08-27 00:23:02.813777: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.07202646002769471, {'accuracy': 0.1615}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.07202646002769471 / accuracy 0.1615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(pid=15691)\u001b[0m 2024-08-27 00:23:09.477288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m /usr/local/lib/python3.10/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m [Client 0, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 1: train loss 0.03513731434941292, accuracy 0.6765\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m [Client 3, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 1: train loss 0.03392567113041878, accuracy 0.6898333333333333\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m [Client 6, round 1] fit, config: {'server_round': 1, 'local_epochs': 1}\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 1: train loss 0.03519357740879059, accuracy 0.6795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.014736710050702095, {'accuracy': 0.8693}, 46.07981303700035)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.014736710050702095 / accuracy 0.8693\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m [Client 0, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 1: train loss 0.013785460032522678, accuracy 0.873\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 2: train loss 0.010981257073581219, accuracy 0.897\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m [Client 5, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 1: train loss 0.013669862411916256, accuracy 0.8751666666666666\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 2: train loss 0.010655165649950504, accuracy 0.9015\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m [Client 9, round 2] fit, config: {'server_round': 2, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 1: train loss 0.013523644767701626, accuracy 0.8791666666666667\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 2: train loss 0.010517115704715252, accuracy 0.9055\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.010014868995547295, {'accuracy': 0.9044}, 103.55692098600002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.010014868995547295 / accuracy 0.9044\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m [Client 0, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 1: train loss 0.010251138359308243, accuracy 0.9038333333333334\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 2: train loss 0.008859232999384403, accuracy 0.9173333333333333\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m [Client 2, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 1: train loss 0.01109837181866169, accuracy 0.8965\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 2: train loss 0.00918219331651926, accuracy 0.914\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m [Client 7, round 3] fit, config: {'server_round': 3, 'local_epochs': 2}\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 1: train loss 0.010787480510771275, accuracy 0.8946666666666667\n",
            "\u001b[36m(ClientAppActor pid=15691)\u001b[0m Epoch 2: train loss 0.009149247780442238, accuracy 0.9113333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.008601170311495663, {'accuracy': 0.9194}, 160.7633316260003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: no clients selected, skipping evaluation\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 3 round(s) in 160.77s\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 0: 0.07202646002769471\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.014736710050702095\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.010014868995547295\n",
            "\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.008601170311495663\n",
            "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.1615), (1, 0.8693), (2, 0.9044), (3, 0.9194)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server-side evaluation loss 0.008601170311495663 / accuracy 0.9194\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 64-bit ('flower-3.7.12')",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}